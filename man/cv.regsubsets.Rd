% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/subset_selection.R
\name{cv.regsubsets}
\alias{cv.regsubsets}
\title{Cross-validation for selecting best model in subset selection}
\usage{
cv.regsubsets(
  x,
  y,
  nfolds = 10,
  foldid = NULL,
  method = c("exhaustive", "backward"),
  standardize = F
)
}
\arguments{
\item{x}{A matrix of predictors with column names}

\item{y}{A vector of quantitative response variable.}

\item{nfolds}{The number of cross-validation folds.}

\item{foldid}{An optional vector identifying the fold each observation belongs to.
Values should range from 1 to k. If supplied, k can be missing.}

\item{method}{The method for variable selection, either "exhaustive" or "backward".}

\item{standardize}{Specifies whether to standardize the predictors matrix `x`
to have mean 0 and unit variance. If set to TRUE, `x` will be standardized.
Additionally, the response variable `y` will be centered by subtracting its
mean. This standardization step can be useful to ensure that the predictors
are on a comparable scale. By default, `standardize` is set to FALSE,
indicating that no standardization will be performed.}
}
\description{
Select the best model using K-fold cross-validation. The mean squared error
(MSE) is utilized as the loss function. The model with the smallest average
MSE is considered the best model.
}
\references{
James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013).
An Introduction to Statistical Learning (Vol. 112, p. 18). New York: Springer.
}
